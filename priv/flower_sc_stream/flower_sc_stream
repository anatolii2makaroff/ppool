#!/usr/bin/python
#
# Flow scheduler worker
#

import sys
import time
import json
import sqlite3
import glob

# API


def log(m):
    sys.stderr.write("{}: {}\n".format(time.time(), m))


def read():
    line = sys.stdin.readline()
    return line.strip()


def send(m):
    sys.stdout.write("{}\n".format(m))
    sys.stdout.flush()


# Process - actor
#  line - recieve message from world
#  send - send message to world
#  log  -  logging anything


def main(p, node, t):
    """
        t - time interval in secs
    """

    msg = read()

    log("get message: " + msg)

    while 1:

        # gel local flows
        # init flows

        log("start init flows..")

        for f in get_flows(p):
            f_name, f_active = f.get("name"), f.get("active")

            log("init {} {}".format(f_name, f_active))

            if f_active == 1:
                send("system::{}::start".format(f_name))
            else:
                send("system::{}::stop".format(f_name))

        #  get main node
        m_node = get_main_node(p)
        if m_node != node:
            log("main node {} ..sleep".format(m_node))
            time.sleep(int(t))
            continue

        #  get node stats
        for i in get_stats(p):

            log("stats {}".format(i))

        log("tick..")

        time.sleep(int(t))


def connect(p):
    return sqlite3.connect(p + '/db/node_collector.db')


def get_main_node(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute("""select s.node, s.date
                         from node_stat s left join (select node, active, MAX(date) from node_list) l
                          on s.node = l.node
                         where s.date > DATETIME('NOW', '-1 minutes')
                            and ifnull(l.active, 1) = 1
                         group by s.node
                         order by s.date, s.node desc
                         LIMIT 1
                """)

    data = None
    for row in cur:
        data = row[0]

    con.close()

    return data


def get_stats(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute("""

        select s.node, l.name
               ,MAX(ok)
               ,MAX(l.error), MAX(l.timeout), MAX(running), SUM(l.nomore)
               ,round(AVG(elapsed)/1000,2)

               ,AVG(s.count), AVG(s.cpu_percent), AVG(s.ram_percent)

               ,AVG(ns.cpu_percent), AVG(ns.ram_percent)
               ,ns.cpu_count, ns.ram_count

             from ppool_list l, ppool_stat s,
                  node_stat ns
             where l.node = s.node
                 and l.name = substr(s.name,0,instr(s.name, ":"))
                 and s.node = ns.node
                 and l.date > DATETIME('NOW', '-5 minutes')
             group by s.node, s.name


               """)

    data = []
    for row in cur:
        data.append(row)

    con.close()

    return data


def get_flows(p):
    l = glob.glob(p + "/flows/*.json")

    data = []
    for i in l:
        with open(i) as f:
            data.append(json.loads(f.read()))

    return data


if __name__ == "__main__":
    main(sys.argv[1], sys.argv[2], sys.argv[3])
