#!/usr/bin/python
#
# Flow scheduler worker
#

import sys
import time
import json
import sqlite3
import glob
from operator import mul
import math


# API

def read():
    line = sys.stdin.readline()
    return line.strip()


def log(m):
    sys.stderr.write("{}: {}\n".format(time.time(), m))
    sys.stderr.flush()


def send(m):
    sys.stdout.write("{}\n".format(m))
    sys.stdout.flush()

# Process - actor
#  read - recieve message from world
#  send - send message to world
#  log  -  logging anything


def main(p, node, t):
    """
        t - time interval in secs
    """
    tb = time.time()

    msg = read()

    log("get message: " + msg)

    while 1:

        #  set clester network balancer
        #  get main node floating ip
        log("get main node..")
        m_nodes = get_active_nodes(p)

        log("get active nodes: {}".format(m_nodes))

        if len(m_nodes) == 0:
            m_node = None
        else:
            m_node = m_nodes[0]

        if m_node != node:
            log("i'm not main node {} ..set rserv".format(m_node))
            time.sleep(int(t))
            send("ok")

            continue
        else:
            log("main node {} ..set admin".format(m_node))

        if time.time() - tb < int(t) * 5:
            time.sleep(int(t))
            send("ok")

            continue
        else:
            tb = time.time()

        #  get node's statistic
        log("get stats..")

        # pstats = get_stats(p)

        #  gel flows scenes
        #  start/stop flows

        log("start init flows..")

        # start_init_flows(p, pstats, m_nodes)

        pstats = get_stats_decrease(p)

        log("start decrease flows..")

        decrease_ppools(pstats, m_nodes)

        send("ok")
        log("tick..")

        time.sleep(int(t))


def connect(p):
    return sqlite3.connect(p + '/db/node_collector.db')


def decrease_ppools(pstats, m_nodes):

    for k, v in pstats.iteritems():

        # if k not in m_nodes:
        #     continue

        log("decrease ppool : {} {}".format(k, v))


def start_init_flows(p, pstats, m_nodes):

    for f in get_flows(p):
        f_name, f_active, f_ppools, f_count, f_ram = f.get("name"), f.get("active"),\
            [[y.get("cmd").split("::")[3] for y in x.get("cook")
              if y.get("cmd").split("::")[2] == "start_pool"]
             for x in f.get("scenes")
             if x["name"] == f.get("start_scene")][0],\
            [[int(y.get("cmd").split("::")[4]) for y in x.get("cook")
              if y.get("cmd").split("::")[2] == "start_pool"]
             for x in f.get("scenes")
             if x["name"] == f.get("start_scene")][0],\
            [[int(y.get("cmd").split("::")[4].split(" ")[1][:-1]) for y in x.get("cook")
              if y.get("cmd").split("::")[2] == "start_all_workers"]
             for x in f.get("scenes")
             if x["name"] == f.get("start_scene")][0]

        log("read flow {} {} {} {} {}".format(f_name, f_active, f_ppools, f_count, f_ram))

        # if flow not active stop on all nodes
        if f_active == 0:
            log("stop on all nodes..{}".format(f_name))
            send("system::all::{}::stop".format(f_name))

        elif f_active == 1:
            # check already started

            first_start = True
            for k, v in pstats.iteritems():

                if k not in m_nodes:
                    continue

                if set(f_ppools).issubset(set([x[1] for x in v])):

                    log("on node {} flow {} is started".format(k, f_name))
                    send("system::{}::{}::start".format(k, f_name))

                    first_start = False

                else:
                    log("on node {} flow {} is NOT started".format(k, f_name))

                    # force clear
                    send("system::{}::{}::stop".format(k, f_name))

                    first_start = False or first_start

            # need first start

            if first_start:
                log("flow {} first start {}".format(f_name, first_start))

                _ram_need = sum(map(mul, f_ram, f_count))

                # check resources for first start
                # ram cpu

                v = get_load_nodes(p)
                for n, l in v.iteritems():
                    log("load nodes {} {} {}".format(n, l, _ram_need))

                    if l[1] > _ram_need and l[0] < 85:
                        send("system::{}::{}::start".format(n, f_name))
                        break
                    else:
                        continue


def get_load_nodes(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute(""" select * from(
                     select s.node, AVG(s.cpu_percent) cpu, (1 - AVG(s.ram_percent)/100) * s.ram_count ram
                         from node_stat s left join (select node, active, MAX(date) from node_list
                                                      where date > DATETIME('NOW', '-1 minutes')
                                                    ) l
                          on s.node = l.node
                         where s.date > DATETIME('NOW', '-1 minutes')
                            and ifnull(l.active, 1) = 1
                         group by s.node
                   ) t
                   order by t.ram desc, t.cpu asc
                """)

    data = {}

    for row in cur:
        data[row[0]] = (row[1], row[2])

    con.close()

    return data


def get_active_nodes(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute("""select s.node, s.date
                         from node_stat s left join (select node, active, MAX(date) from node_list
                                                      where date > DATETIME('NOW', '-1 minutes')
                                                    ) l
                          on s.node = l.node
                         where s.date > DATETIME('NOW', '-1 minutes')
                            and ifnull(l.active, 1) = 1
                         group by s.node
                         order by s.date, s.node desc
                         -- LIMIT 1
                """)

    data = []

    for row in cur:
        data.append(row[0])

    con.close()

    return data


def get_stats_decrease(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute("""

        select t.node, t.name, t.cnt, t.ok/(300*1000/t.time), t.nm

          from (
             select s.node, l.name
                    ,MAX(ok) ok
                    ,MAX(running) run
                    ,SUM(l.nomore) nm
                    ,round(MAX(elapsed)/1000,2) time
                    ,MIN(s.count) cnt

                  from ppool_list l, ppool_stat s,
                       node_stat ns
                  where l.node = s.node
                      and l.name = s.name
                      and s.node = ns.node
                      and l.date > DATETIME('NOW', '-1 minutes')
                  group by s.node, s.name
               ) t


               """)

    data = {}
    for row in cur:

        if row[2] is None or row[3] is None:
            continue

        log("decrease stat {}".format(row))

        workers = math.ceil(row[2]) - math.ceil(row[3])

        if workers > 0:
            if data.get(row[1]) is None:
                data[row[1]] = [(row[0], math.ceil(row[2]), workers)]
            else:
                data.get(row[1]).append((row[0], math.ceil(row[2]), workers))

    con.close()

    return data


def get_stats(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute("""

        select s.node, l.name
               ,MAX(ok)
               ,MAX(l.error), MAX(l.timeout), MAX(running), SUM(l.nomore)
               ,round(AVG(elapsed)/1000,2)

               ,AVG(s.count), AVG(s.cpu_percent), AVG(s.ram_percent)

               ,AVG(ns.cpu_percent), AVG(ns.ram_percent)
               ,ns.cpu_count, ns.ram_count

             from ppool_list l, ppool_stat s,
                  node_stat ns
             where l.node = s.node
                 and l.name = s.name
                 and s.node = ns.node
                 and l.date > DATETIME('NOW', '-5 minutes')
             group by s.node, s.name


               """)

    data = {}
    for row in cur:
        if data.get(row[0]) is None:
            data[row[0]] = [row]
        else:
            data[row[0]].append(row)

    con.close()

    return data


def get_flows(p):
    l = glob.glob(p + "/flows/*.json")

    data = []
    for i in l:
        with open(i) as f:
            data.append(json.loads(f.read()))

    return data


if __name__ == "__main__":
    main(sys.argv[1], sys.argv[2], sys.argv[3])
