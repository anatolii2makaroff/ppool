#!/usr/bin/python
#
# Flow scheduler worker
#

import sys
import time
import json
import sqlite3
import glob
from operator import mul


# API


def log(m):
    sys.stderr.write("{}: {}\n".format(time.time(), m))


def read():
    line = sys.stdin.readline()
    return line.strip()


def send(m):
    sys.stdout.write("{}\n".format(m))
    sys.stdout.flush()


# Process - actor
#  read - recieve message from world
#  send - send message to world
#  log  -  logging anything


def main(p, node, t):
    """
        t - time interval in secs
    """
    tb = time.time()

    msg = read()

    log("get message: " + msg)

    while 1:

        #  set clester network balancer
        #  get main node floating ip
        log("get main node..")

        m_node = get_main_node(p)
        if m_node != node:
            log("i'm not main node {} ..set rserv".format(m_node))
            time.sleep(int(t))
            send("ok")

            continue
        else:
            log("main node {} ..set admin".format(m_node))

        if time.time() - tb < int(t) * 5:
            time.sleep(int(t))
            send("ok")

            continue
        else:
            tb = time.time()

        #  get node's statistic
        log("get stats..")

        pstats = get_stats(p)

        #  gel flows scenes
        #  start/stop flows

        log("start init flows..")

        for f in get_flows(p):
            f_name, f_active, f_ppools, f_count, f_ram = f.get("name"), f.get("active"),\
                [[y.get("cmd").split("::")[3] for y in x.get("cook")
                  if y.get("cmd").split("::")[2] == "start_pool"]
                 for x in f.get("scenes")
                 if x["name"] == f.get("start_scene")][0],\
                [[int(y.get("cmd").split("::")[4]) for y in x.get("cook")
                  if y.get("cmd").split("::")[2] == "start_pool"]
                 for x in f.get("scenes")
                 if x["name"] == f.get("start_scene")][0],\
                [[int(y.get("cmd").split("::")[4].split(" ")[1][:-1]) for y in x.get("cook")
                  if y.get("cmd").split("::")[2] == "start_all_workers"]
                 for x in f.get("scenes")
                 if x["name"] == f.get("start_scene")][0]

            log("read flow {} {} {} {} {}".format(f_name, f_active, f_ppools, f_count, f_ram))

            # if flow not active stop on all nodes
            if f_active == 0:
                log("stop on all nodes..{}".format(f_name))
                send("system::all::{}::stop".format(f_name))

            elif f_active == 1:
                # check already started

                first_start = True
                for k, v in pstats.iteritems():

                    if set(f_ppools).issubset(set([x[1] for x in v])):

                        log("on node {} flow {} is started".format(k, f_name))
                        send("system::{}::{}::start".format(k, f_name))

                        first_start = False

                    else:
                        log("on node {} flow {} is NOT started".format(k, f_name))

                        # force clear
                        send("system::{}::{}::stop".format(k, f_name))

                        first_start = False or first_start

                if first_start:
                    log("flow {} first start {}".format(f_name, first_start))

                    _ram_need = sum(map(mul, f_ram, f_count))

                    # check resources for first start
                    # ram cpu

                    v = get_load_nodes(p)
                    for n, l in v.iteritems():
                        log("load nodes {} {} {}".format(n, l, _ram_need))

                        if l[1] > _ram_need:
                            send("system::{}::{}::start".format(n, f_name))
                            break
                        else:
                            continue
        send("ok")
        log("tick..")

        time.sleep(int(t))


def connect(p):
    return sqlite3.connect(p + '/db/node_collector.db')


def get_load_nodes(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute(""" select * from(
                     select s.node, AVG(s.cpu_percent) cpu, (1 - AVG(s.ram_percent)/100) * s.ram_count ram
                         from node_stat s left join (select node, active, MAX(date) from node_list
                                                      where date > DATETIME('NOW', '-1 minutes')
                                                    ) l
                          on s.node = l.node
                         where s.date > DATETIME('NOW', '-1 minutes')
                            and ifnull(l.active, 1) = 1
                         group by s.node
                   ) t
                   order by t.ram desc, t.cpu asc
                """)

    data = {}

    for row in cur:
        data[row[0]] = (row[1], row[2])

    con.close()

    return data


def get_main_node(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute("""select s.node, s.date
                         from node_stat s left join (select node, active, MAX(date) from node_list
                                                      where date > DATETIME('NOW', '-1 minutes')
                                                    ) l
                          on s.node = l.node
                         where s.date > DATETIME('NOW', '-1 minutes')
                            and ifnull(l.active, 1) = 1
                         group by s.node
                         order by s.date, s.node desc
                         LIMIT 1
                """)

    data = None

    for row in cur:
        data = row[0]

    con.close()

    return data


def get_stats(p):
    con = connect(p)
    cur = con.cursor()

    cur.execute("""

        select s.node, l.name
               ,MAX(ok)
               ,MAX(l.error), MAX(l.timeout), MAX(running), SUM(l.nomore)
               ,round(AVG(elapsed)/1000,2)

               ,AVG(s.count), AVG(s.cpu_percent), AVG(s.ram_percent)

               ,AVG(ns.cpu_percent), AVG(ns.ram_percent)
               ,ns.cpu_count, ns.ram_count

             from ppool_list l, ppool_stat s,
                  node_stat ns
             where l.node = s.node
                 and l.name = s.name
                 and s.node = ns.node
                 and l.date > DATETIME('NOW', '-5 minutes')
             group by s.node, s.name


               """)

    data = {}
    for row in cur:
        if data.get(row[0]) is None:
            data[row[0]] = [row]
        else:
            data[row[0]].append(row)

    con.close()

    return data


def get_flows(p):
    l = glob.glob(p + "/flows/*.json")

    data = []
    for i in l:
        with open(i) as f:
            data.append(json.loads(f.read()))

    return data


if __name__ == "__main__":
    main(sys.argv[1], sys.argv[2], sys.argv[3])
